{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "#from torch.utils.data import Dataset, DataLoader\n",
    "#import torch.utils.data\n",
    "import torch.nn.functional as F\n",
    "import torch.cuda as cutorch\n",
    "\n",
    "\n",
    "import gc\n",
    "\n",
    "import random\n",
    "import model as model_code\n",
    "import nsd_loss\n",
    "\n",
    "from utils import seed_all_randomness, create_exp_dir, save_checkpoint, load_idx2word_freq, load_emb_file_to_tensor, load_corpus, output_parallel_models, str2bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    def __init__(self):\n",
    "        # path\n",
    "        self.data = '/iesl/canvas/hanqingli/NSD_for_sentence_embedding/data/wiki2016_min100/1_1/'\n",
    "        self.tensor_folder='corpus_00'\n",
    "        self.training_file='train.pt'\n",
    "        self.save='/iesl/canvas/hanqingli/NSD_for_sentence_embedding/saves/test1'\n",
    "        self.emb_file='/iesl/canvas/hschang/language_modeling/NSD_for_sentence_embedding/resources/glove.840B.300d_filtered_wiki2016.txt'\n",
    "        # parser.add_argument('--stop_word_file', type=str, default='./resources/stop_word_list',\n",
    "        #                    help='path to the file of a stop word list')\n",
    "\n",
    "        # encoder\n",
    "        # both\n",
    "#         parser.add_argument('--en_model', type=str, default='LSTM',\n",
    "#                             help='type of encoder model (LSTM, LSTM+TRANS, TRANS+LSTM, TRANS)')\n",
    "        self.en_model='TRANS'\n",
    "#         parser.add_argument('--emsize', type=int, default=0,\n",
    "#                             help='size of word embeddings')\n",
    "        self.emsize=0\n",
    "#         parser.add_argument('--dropouti', type=float, default=0.4,\n",
    "#                             help='dropout for input embedding layers (0 = no dropout)')\n",
    "        self.dropouti=0.1\n",
    "#         parser.add_argument('--dropoute', type=float, default=0.1,\n",
    "#                             help='dropout to remove words from embedding layer (0 = no dropout)')\n",
    "        self.dropoute=0\n",
    "        # LSTM only\n",
    "#         parser.add_argument('--nhid', type=int, default=600,\n",
    "#                             help='number of hidden units per layer in LSTM')\n",
    "        self.nhid=600\n",
    "#         parser.add_argument('--nlayers', type=int, default=1,\n",
    "#                             help='number of layers')\n",
    "        self.nlayers=1\n",
    "#         parser.add_argument('--dropout', type=float, default=0.4,\n",
    "#                             help='dropout applied to the output layer (0 = no dropout)')\n",
    "        self.dropout=0\n",
    "        # TRANS only\n",
    "#         parser.add_argument('--encode_trans_layers', type=int, default=5,\n",
    "#                             help='How many layers we have in transformer. Do not have effect if de_model is LSTM')\n",
    "        self.encode_trans_layers=5\n",
    "#         parser.add_argument('--trans_nhid', type=int, default=-1,\n",
    "#                             help='number of hidden units per layer in transformer')\n",
    "        self.trans_nhid=-1\n",
    "#         parser.add_argument('--nhidlast', type=int, default=-1,\n",
    "#                             help='number of hidden units for the last rnn layer')\n",
    "        self.nhidlast=-1\n",
    "#         parser.add_argument('--dropouth', type=float, default=0.3,\n",
    "#                             help='dropout for rnn layers (0 = no dropout)')\n",
    "        self.dropouth=0.3\n",
    "#         parser.add_argument('--dropoutl', type=float, default=-0.2,\n",
    "#                             help='dropout applied to layers (0 = no dropout)')\n",
    "        self.dropoutl=-0.25\n",
    "#         parser.add_argument('--wdrop', type=float, default=0.5,\n",
    "#                             help='amount of weight dropout to apply to the RNN hidden to hidden matrix')\n",
    "        self.wdrop=0.5\n",
    "\n",
    "        # decoder\n",
    "        # both\n",
    "#         parser.add_argument('--de_model', type=str, default='LSTM',\n",
    "#                             help='type of decoder model (LSTM, LSTM+TRANS, TRANS+LSTM, TRANS)')\n",
    "#         parser.add_argument('--de_coeff_model', type=str, default='LSTM',\n",
    "#                             help='type of decoder model to predict coefficients (LSTM, TRANS)')\n",
    "#         parser.add_argument('--n_basis', type=int, default=10,\n",
    "#                             help='number of basis we want to predict')\n",
    "#         # parser.add_argument('--linear_mapping_dim', type=int, default=0,\n",
    "#         #                    help='map the input embedding by linear transformation')\n",
    "#         parser.add_argument('--positional_option', type=str, default='linear',\n",
    "#                             help='options of encode positional embedding into models (linear, cat, add)')\n",
    "#         parser.add_argument('--dropoutp', type=float, default=0.5,\n",
    "#                             help='dropout of positional embedding or input embedding after linear transformation (when linear_mapping_dim != 0)')\n",
    "#         # LSTM only\n",
    "#         parser.add_argument('--nhidlast2', type=int, default=-1,\n",
    "#                             help='hidden embedding size of the second LSTM')\n",
    "#         # TRANS only\n",
    "#         parser.add_argument('--trans_layers', type=int, default=5,\n",
    "#                             help='How many layers we have in transformer. Do not have effect if de_model is LSTM')\n",
    "#         parser.add_argument('--de_en_connection', type=str2bool, nargs='?', default=True,\n",
    "#                             help='If True, using Transformer decoder in our decoder. Otherwise, using Transformer encoder')\n",
    "#         parser.add_argument('--dropout_prob_trans', type=float, default=0.1,\n",
    "#                             help='hidden_dropout_prob and attention_probs_dropout_prob in Transformer')\n",
    "        # coeff\n",
    "#         parser.add_argument('--w_loss_coeff', type=float, default=0.1,\n",
    "#                             help='weights for coefficient prediction loss')\n",
    "        self.w_loss_coeff=0.1\n",
    "#         parser.add_argument('--L1_losss_B', type=float, default=0.2,\n",
    "#                             help='L1 loss for the coefficient matrix')\n",
    "        self.L1_losss_B=0.25\n",
    "        # parser.add_argument('--coeff_opt', type=str, default='max',\n",
    "#         parser.add_argument('--coeff_opt', type=str, default='lc',\n",
    "#                             help='Could be max, lc, maxlc')\n",
    "        self.coeff_opt='lc'\n",
    "#         parser.add_argument('--coeff_opt_algo', type=str, default='rmsprop',\n",
    "#                             # parser.add_argument('--coeff_opt_algo', type=str, default='sgd_bmm',\n",
    "#                             help='Could be sgd_bmm, sgd, asgd, adagrad, rmsprop, and adam')\n",
    "        self.coeff_opt_algo='rmsprop'\n",
    "        # target emb\n",
    "#         parser.add_argument('--update_target_emb', default=False, action='store_true',\n",
    "#                             help='Whether to update target embedding')\n",
    "        self.update_target_emb=False\n",
    "#         parser.add_argument('--target_emb_source', type=str, default='ext',\n",
    "#                             help='Could be ext (external), rand or ewe (encode word embedding)')\n",
    "        self.target_emb_source='ext'\n",
    "\n",
    "        # training\n",
    "#         parser.add_argument('--optimizer', type=str, default=\"SGD\",\n",
    "#                             help='optimization algorithm. Could be SGD or Adam')\n",
    "        self.optimizer='SGD'\n",
    "#         parser.add_argument('--lr', type=float, default=1,\n",
    "#                             help='initial learning rate')\n",
    "        self.lr=1.0\n",
    "#         parser.add_argument('--lr2_divide', type=float, default=1.0,\n",
    "#                             help='drop this ratio for the learning rate of the second LSTM')\n",
    "        self.lr2_divide=1.0\n",
    "#         parser.add_argument('--clip', type=float, default=0.25,\n",
    "#                             help='gradient clipping')\n",
    "        self.clip=0.25\n",
    "#         parser.add_argument('--epochs', type=int, default=100,\n",
    "#                             help='upper epoch limit')\n",
    "        self.epochs=100\n",
    "#         parser.add_argument('--batch_size', type=int, default=200, metavar='N',\n",
    "#                             help='batch size')\n",
    "        self.batch_size=200\n",
    "#         parser.add_argument('--small_batch_size', type=int, default=-1,\n",
    "#                             help='the batch size for computation. batch_size should be divisible by small_batch_size.\\\n",
    "#                              In our implementation, we compute gradients with small_batch_size multiple times, and accumulate the gradients\\\n",
    "#                              until batch_size is reached. An update step is then performed.')\n",
    "        self.small_batch_size=-1\n",
    "#         parser.add_argument('--wdecay', type=float, default=1e-6,\n",
    "#                             help='weight decay applied to all weights')\n",
    "        self.wdecay=1e-6\n",
    "#         parser.add_argument('--nonmono', type=int, default=1,\n",
    "#                             help='decay learning rate after seeing how many validation performance drop')\n",
    "        self.nonmono=1\n",
    "#         parser.add_argument('--training_split_num', type=int, default=2,\n",
    "#                             help='We want to split training corpus into how many subsets. Splitting training dataset seems to make pytorch run much faster and we can store and eval the model more frequently')\n",
    "        self.training_split_num=200\n",
    "#         parser.add_argument('--valid_per_epoch', type=int, default=2,\n",
    "#                             help='Number of times we want to run through validation data and save model within an epoch')\n",
    "        self.valid_per_epoch=200\n",
    "#         parser.add_argument('--copy_training', type=str2bool, nargs='?', default=True,\n",
    "#                             help='turn off this option to save some cpu memory when loading training data')\n",
    "        self.copy_training=True\n",
    "\n",
    "        # system\n",
    "#         parser.add_argument('--seed', type=int, default=1111,\n",
    "#                             help='random seed')\n",
    "        self.seed=1111\n",
    "#         parser.add_argument('--cuda', type=str2bool, nargs='?', default=True,\n",
    "#                             help='use CUDA')\n",
    "        self.cuda=True\n",
    "#         parser.add_argument('--single_gpu', default=False, action='store_true',\n",
    "#                             help='use single GPU')\n",
    "        self.single_gpu=False\n",
    "#         parser.add_argument('--log-interval', type=int, default=200, metavar='N',\n",
    "#                             help='report interval')\n",
    "#         self.log-interval=200\n",
    "#         parser.add_argument('--continue_train', action='store_true',\n",
    "#                             help='continue train from a checkpoint')\n",
    "        self.continue_train=False\n",
    "#         parser.add_argument('--start_training_split', type=int, default=0,\n",
    "#                             help='We want to split training corpus into how many subsets. Splitting training dataset seems to make pytorch run much faster and we can store and eval the model more frequently')\n",
    "        self.start_training_split=0\n",
    "\n",
    "args = arguments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set up environment\n",
      "Experiment dir : /iesl/canvas/hanqingli/NSD_for_sentence_embedding/saves/test1-20200309-164335\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "print(\"Set up environment\")\n",
    "########################\n",
    "assert args.training_split_num >= args.valid_per_epoch\n",
    "\n",
    "if not args.continue_train:\n",
    "    args.save = '{}-{}'.format(args.save, time.strftime(\"%Y%m%d-%H%M%S\"))\n",
    "create_exp_dir(args.save, scripts_to_save=['main.ipynb', 'model.py', 'nsd_loss.py'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.coeff_opt == 'maxlc':\n",
    "    current_coeff_opt = 'max'\n",
    "else:\n",
    "    current_coeff_opt = args.coeff_opt\n",
    "\n",
    "#if args.dropoutl < 0:\n",
    "#    args.dropoutl = args.dropouth\n",
    "if args.small_batch_size < 0:\n",
    "    args.small_batch_size = args.batch_size\n",
    "\n",
    "\n",
    "assert args.batch_size % args.small_batch_size == 0, 'batch_size must be divisible by small_batch_size'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args: <__main__.arguments object at 0x7fdb7acf1a90>\n"
     ]
    }
   ],
   "source": [
    "def logging(s, print_=True, log_=True):\n",
    "    if print_:\n",
    "        print(s)\n",
    "        sys.stdout.flush()\n",
    "    if log_:\n",
    "        with open(os.path.join(args.save, 'log.txt'), 'a+') as f_log:\n",
    "            f_log.write(s + '\\n')\n",
    "            \n",
    "# Set the random seed manually for reproducibility.\n",
    "seed_all_randomness(args.seed,args.cuda)\n",
    "\n",
    "logging('Args: {}'.format(args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "OOV word type percentage: 10.343283933746436%\n",
      "OOV token percentage: 0.748010626181413%\n",
      "loading  /iesl/canvas/hschang/language_modeling/NSD_for_sentence_embedding/resources/glove.840B.300d_filtered_wiki2016.txt\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data\")\n",
    "\n",
    "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "\n",
    "idx2word_freq, dataloader_train_arr, dataloader_val, dataloader_val_shuffled, max_sent_len = load_corpus(args.data, args.batch_size, args.batch_size, device, args.tensor_folder, args.training_file, args.training_split_num, args.copy_training)\n",
    "\n",
    "\n",
    "def counter_to_tensor(idx2word_freq,device):\n",
    "    total = len(idx2word_freq)\n",
    "    w_freq = torch.zeros(total, dtype=torch.float, device = device, requires_grad = False)\n",
    "    for i in range(total):\n",
    "        w_freq[i] = 1\n",
    "        #w_freq[i] = math.sqrt(idx2word_freq[x][1])\n",
    "        #w_freq[i] = idx2word_freq[x][1]\n",
    "    w_freq[0] = -1\n",
    "    return w_freq\n",
    "\n",
    "external_emb = torch.tensor([0.])\n",
    "extra_init_idx = []\n",
    "if len(args.emb_file) > 0:\n",
    "    #with torch.no_grad():\n",
    "    external_emb, output_emb_size, extra_init_idx = load_emb_file_to_tensor(args.emb_file, device, idx2word_freq)\n",
    "    external_emb = external_emb / (0.000000000001 + external_emb.norm(dim = 1, keepdim=True))\n",
    "    external_emb.requires_grad = args.update_target_emb\n",
    "    print(\"loading \", args.emb_file)\n",
    "else:\n",
    "    if args.target_emb_source == 'ewe':\n",
    "        output_emb_size = args.emsize\n",
    "        print(\"Using word embedding from encoder\")\n",
    "    elif args.target_emb_source == 'rand' and args.update_target_emb == True:\n",
    "        output_emb_size = args.emsize\n",
    "        external_emb = torch.randn(len(idx2word_freq), output_emb_size, device = device, requires_grad = False)\n",
    "        external_emb = external_emb / (0.000000000001 + external_emb.norm(dim = 1, keepdim=True))\n",
    "        external_emb.requires_grad = True\n",
    "        print(\"Initialize target embedding randomly\")\n",
    "    else:\n",
    "        print(\"we don't support such target_emb_source \" + args.target_emb_source + \", update_target_emb \", args.update_target_emb, \", and emb_file \"+ args.emb_file)\n",
    "        sys.exit(1)\n",
    "\n",
    "if args.trans_nhid < 0:\n",
    "    if args.emsize > 0:\n",
    "        args.trans_nhid = args.emsize\n",
    "    else:\n",
    "        args.trans_nhid = output_emb_size\n",
    "\n",
    "\n",
    "w_freq = counter_to_tensor(idx2word_freq,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building models\n",
      "Randomly initializes embedding for  30730  words\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "print(\"Building models\")\n",
    "########################\n",
    "\n",
    "ntokens = len(idx2word_freq)\n",
    "\n",
    "encoder = model_code.SEQ2EMB(args.en_model.split('+'), ntokens, args.emsize, args.nhid, args.nlayers,\n",
    "               args.dropout, args.dropouti, args.dropoute, max_sent_len,  external_emb, extra_init_idx, args.encode_trans_layers, args.trans_nhid)\n",
    "criterion = nn.MSELoss().cuda()\n",
    "# if args.nhidlast2 < 0:\n",
    "#     #args.nhidlast2 = output_emb_size\n",
    "#     args.nhidlast2 = encoder.output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as weight_init\n",
    "def initialize_weights(net, normal_std):\n",
    "    for name, param in net.named_parameters(): \n",
    "        if 'bias' in name or 'rnn' not in name:\n",
    "            #print(\"skip \"+name)\n",
    "            continue\n",
    "        print(\"normal init \"+name+\" with std\"+str(normal_std) )\n",
    "        weight_init.normal_(param, std = normal_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.continue_train:\n",
    "    encoder.load_state_dict(torch.load(os.path.join(args.save, 'encoder.pt')))\n",
    "    # decoder.load_state_dict(torch.load(os.path.join(args.save, 'decoder.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder total parameters: 94580450\n"
     ]
    }
   ],
   "source": [
    "parallel_encoder = output_parallel_models(args.cuda, args.single_gpu, encoder)\n",
    "\n",
    "total_params = sum(x.data.nelement() for x in encoder.parameters())\n",
    "logging('Encoder total parameters: {}'.format(total_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "print(\"Training\")\n",
    "########################\n",
    "\n",
    "def evaluate(dataloader, external_emb, current_coeff_opt):\n",
    "    # Turn on evaluation mode which disables dropout.\n",
    "    encoder.eval()\n",
    "    # decoder.eval()\n",
    "    total_loss = 0\n",
    "    total_loss_set = 0\n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(dataloader):\n",
    "            feature, target = sample_batched\n",
    "            output_emb_last, _ = parallel_encoder(feature)\n",
    "\n",
    "            compute_target_grad = False\n",
    "            loss = criterione(output_emb_last, target)\n",
    "            total_loss += loss * batch_size\n",
    "\n",
    "    return total_loss.item() / len(dataloader.dataset), total_loss_set.item() / len(dataloader.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader_train, external_emb, lr, current_coeff_opt, split_i):\n",
    "    start_time = time.time()\n",
    "    total_loss = 0.\n",
    "    total_loss_set = 0.\n",
    "    total_loss_set_reg = 0.\n",
    "    total_loss_set_div = 0.\n",
    "    total_loss_set_neg = 0.\n",
    "    total_loss_coeff_pred = 0.\n",
    "\n",
    "    encoder.train()\n",
    "    # decoder.train()\n",
    "    for i_batch, sample_batched in enumerate(dataloader_train):\n",
    "        feature, target = sample_batched\n",
    "        optimizer_e.zero_grad()\n",
    "        output_emb_last, _ = parallel_encoder(feature)\n",
    "        loss = criterion(output_emb_last, target)\n",
    "    \n",
    "        loss *= args.small_batch_size / args.batch_size\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(encoder.parameters(), args.clip)\n",
    "        # torch.nn.utils.clip_grad_norm_(decoder.parameters(), args.clip)\n",
    "        optimizer_e.step()\n",
    "        if len(args.emb_file) == 0 and args.target_emb_source == 'ewe':\n",
    "            encoder.encoder.weight.data[0, :] = 0\n",
    "\n",
    "        # optimizer_d.step()\n",
    "\n",
    "        if args.update_target_emb:\n",
    "            # print(external_emb.requires_grad)\n",
    "            # print(external_emb.grad)\n",
    "            if args.optimizer == 'SGD':\n",
    "                external_emb.data -= lr/args.lr2_divide/10.0 * external_emb.grad.data\n",
    "            else:\n",
    "                #external_emb.data -= 0.1/args.lr2_divide/10.0 * external_emb.grad.data\n",
    "                external_emb.data -= 10/args.lr2_divide/10.0 * external_emb.grad.data\n",
    "            if args.target_emb_source != 'ewe':\n",
    "                external_emb.data[0, :] = 0\n",
    "            external_emb.grad.data.zero_()\n",
    "            # with torch.no_grad():\n",
    "            external_emb.data = external_emb.data / \\\n",
    "                (0.000000000001 + external_emb.data.norm(dim=1, keepdim=True))\n",
    "\n",
    "        if i_batch % args.log_interval == 0 and i_batch > 0:\n",
    "            cur_loss = total_loss / args.log_interval\n",
    "            cur_loss_set = total_loss_set / args.log_interval\n",
    "            cur_loss_set_reg = total_loss_set_reg / args.log_interval\n",
    "            cur_loss_set_div = total_loss_set_div / args.log_interval\n",
    "            cur_loss_set_neg = total_loss_set_neg / args.log_interval\n",
    "            cur_loss_coeff_pred = total_loss_coeff_pred / args.log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            logging('| e {:3d} {:3d} | {:5d}/{:5d} b | lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                    'l {:5.2f} | l_f {:5.4f} + {:5.4f} = {:5.4f} | l_coeff {:5.3f} | reg {:5.2f} | div {:5.2f} '.format(\n",
    "                        epoch, split_i, i_batch, len(\n",
    "                            dataloader_train.dataset) // args.batch_size, optimizer_e.param_groups[0]['lr'],\n",
    "                        elapsed * 1000 / args.log_interval, cur_loss, cur_loss_set, cur_loss_set_neg, cur_loss_set + cur_loss_set_neg, cur_loss_coeff_pred, cur_loss_set_reg, cur_loss_set_div))\n",
    "            # if args.coeff_opt == 'maxlc' and current_coeff_opt == 'max' and cur_loss_set + cur_loss_set_neg < -0.02:\n",
    "            if args.coeff_opt == 'maxlc' and current_coeff_opt == 'max' and cur_loss_set + cur_loss_set_neg < -0.02:\n",
    "                current_coeff_opt = 'lc'\n",
    "                print(\"switch to lc\")\n",
    "            total_loss = 0.\n",
    "            total_loss_set = 0.\n",
    "            total_loss_set_reg = 0.\n",
    "            total_loss_set_div = 0.\n",
    "            total_loss_set_neg = 0.\n",
    "            total_loss_coeff_pred = 0.\n",
    "            start_time = time.time()\n",
    "    return current_coeff_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.optimizer == 'SGD':\n",
    "    optimizer_e = torch.optim.SGD(encoder.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "    # optimizer_d = torch.optim.SGD(decoder.parameters(), lr=args.lr/args.lr2_divide, weight_decay=args.wdecay)\n",
    "else:\n",
    "    optimizer_e = torch.optim.Adam(encoder.parameters(), lr=args.lr, weight_decay=args.wdecay)\n",
    "    # optimizer_d = torch.optim.Adam(decoder.parameters(), lr=args.lr/args.lr2_divide, weight_decay=args.wdecay)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.continue_train:\n",
    "    optimizer_e_state_dict = torch.load(os.path.join(args.save, 'optimizer_e.pt'), map_location=device)\n",
    "    optimizer_e.load_state_dict(optimizer_e_state_dict)\n",
    "    # optimizer_d_state_dict = torch.load(os.path.join(args.save, 'optimizer_d.pt'), map_location=device)\n",
    "    # optimizer_d.load_state_dict(optimizer_d_state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanqingli/workspace/NSD_for_sentence_embedding/src/utils.py:131: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature = torch.tensor(self.feature[idx, :], dtype = torch.long, device = self.output_device)\n",
      "/home/hanqingli/workspace/NSD_for_sentence_embedding/src/utils.py:135: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  target = torch.tensor(self.target[idx, :], dtype = torch.long, device = self.output_device)\n",
      "/home/hanqingli/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py:431: UserWarning: Using a target size (torch.Size([200, 30])) that is different to the input size (torch.Size([200, 50])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (50) must match the size of tensor b (30) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d50928e3da81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Skipping epoch \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' split '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mcurrent_coeff_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexternal_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_coeff_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_split_num\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msaving_freq\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-25b6dd697a0a>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(dataloader_train, external_emb, lr, current_coeff_opt, split_i)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#         loss_set, loss_set_reg, loss_set_div, loss_set_neg, loss_coeff_pred = nsd_loss.compute_loss_set(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#             output_emb_last, input_emb, target, args.L1_losss_B, device, w_freq, current_coeff_opt, compute_target_grad, args.coeff_opt_algo)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_emb_last\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#         if torch.isnan(loss_set):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2213\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2215\u001b[0;31m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2216\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 [0, 1, 2]])\n\u001b[1;32m     51\u001b[0m     \"\"\"\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_VariableFunctions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (50) must match the size of tensor b (30) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "lr = args.lr\n",
    "best_val_loss = None\n",
    "nonmono_count = 0\n",
    "saving_freq = int(math.floor(args.training_split_num / args.valid_per_epoch))\n",
    "\n",
    "for epoch in range(1, args.epochs+1):\n",
    "    epoch_start_time = time.time()\n",
    "    for i in range(len(dataloader_train_arr)):\n",
    "        if epoch == 1 and i < args.start_training_split:\n",
    "            print(\"Skipping epoch \"+str(epoch) + ' split '+str(i) )\n",
    "            continue\n",
    "        current_coeff_opt = train_one_epoch(dataloader_train_arr[i], external_emb, lr, current_coeff_opt, i)\n",
    "        \n",
    "        if i != args.training_split_num - 1 and (i + 1) % saving_freq != 0:\n",
    "            continue\n",
    "\n",
    "        val_loss_all, val_loss_set, val_loss_set_neg, val_loss_ceoff_pred, val_loss_set_reg, val_loss_set_div = evaluate(dataloader_val, external_emb, current_coeff_opt)\n",
    "        logging('-' * 89)\n",
    "        logging('| end of epoch {:3d} split {:3d} | time: {:5.2f}s | lr {:5.2f} | valid loss {:5.2f} | l_f {:5.4f} + {:5.4f} = {:5.4f} | l_coeff {:5.2f} | reg {:5.2f} | div {:5.2f} | '\n",
    "                .format(epoch, i, (time.time() - epoch_start_time), lr,\n",
    "                                           val_loss_all, val_loss_set, val_loss_set_neg, val_loss_set + val_loss_set_neg, val_loss_ceoff_pred, val_loss_set_reg, val_loss_set_div))\n",
    "        \n",
    "        val_loss_important = val_loss_set + val_loss_set_neg\n",
    "        \n",
    "        logging('-' * 89)\n",
    "        #dataloader_val_shuffled?\n",
    "        val_loss_all, val_loss_set, val_loss_set_neg, val_loss_ceoff_pred, val_loss_set_reg, val_loss_set_div = evaluate(dataloader_val_shuffled, external_emb, current_coeff_opt)\n",
    "        logging('-' * 89)\n",
    "        logging('| Shuffled | time: {:5.2f}s | lr {:5.2f} | valid loss {:5.2f} | l_f {:5.4f} + {:5.4f} = {:5.4f} | l_coeff {:5.2f} | reg {:5.2f} | div {:5.2f} | '\n",
    "                .format((time.time() - epoch_start_time), lr,\n",
    "                                           val_loss_all, val_loss_set, val_loss_set_neg, val_loss_set + val_loss_set_neg, val_loss_ceoff_pred, val_loss_set_reg, val_loss_set_div))\n",
    "        logging('-' * 89)\n",
    "        \n",
    "        if not best_val_loss or val_loss_important < best_val_loss:\n",
    "            # save_checkpoint(encoder, decoder, optimizer_e, optimizer_d, external_emb, args.save)\n",
    "            save_checkpoint(encoder, optimizer_e, external_emb, args.save)\n",
    "            best_val_loss = val_loss_important\n",
    "            logging('Models Saved')\n",
    "        else:\n",
    "            nonmono_count += 1\n",
    "        \n",
    "        if nonmono_count >= args.nonmono:\n",
    "            # Anneal the learning rate if no improvement has been seen in the validation dataset.\n",
    "            nonmono_count = 0\n",
    "            lr /= 4.0\n",
    "            for param_group in optimizer_e.param_groups:\n",
    "                param_group['lr'] = lr\n",
    "            # for param_group in optimizer_d.param_groups:\n",
    "            #     param_group['lr'] = lr/args.lr2_divide\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in gc.get_objects():\n",
    "    try:\n",
    "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
    "            if 'cuda' in str(obj.device):\n",
    "                print(obj.device)\n",
    "                del obj\n",
    "                torch.cuda.empty_cache()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "notify_time": "5",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "853px",
    "left": "1550px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
